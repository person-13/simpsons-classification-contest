# -*- coding: utf-8 -*-
"""simpsons_classification_contest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zxWFifPZrRuUda4O0uOb32Zb0IzTuUhb

**Путешествие по Спрингфилду.**


Сегодня вам предстоить помочь телекомпании FOX  в обработке их контента. Как вы знаете сериал Симсоны идет на телеэкранах более 25 лет и за это время скопилось очень много видео материала. Персоонажи менялись вместе с изменяющимися графическими технологиями   и Гомер 2018 не очень похож на Гомера 1989. Нашей задачей будет научиться классифицировать персонажей проживающих в Спрингфилде. Думаю, что нет смысла представлять каждого из них в отдельности.



 ![alt text](https://vignette.wikia.nocookie.net/simpsons/images/5/5a/Spider_fat_piglet.png/revision/latest/scale-to-width-down/640?cb=20111118140828)

# Установка зависимостей
"""

!pip install -U torch torchvision

!pip install wheel==0.34.2 # Тут не обязательно перезапускать

# установка подходящей версии torch

from os.path import exists
from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag
platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())
cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\.\([0-9]*\)\.\([0-9]*\)$/cu\1\2/'
accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'

!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision
import torch

# we will verify that GPU is enabled for this notebook
# following should print: CUDA is available!  Training on GPU ...
# 
# if it prints otherwise, then you need to enable GPU: 
# from Menu > Runtime > Change Runtime Type > Hardware Accelerator > GPU

import torch
import numpy as np

train_on_gpu = torch.cuda.is_available()

if not train_on_gpu:
    print('CUDA is not available.  Training on CPU ...')
else:
    print('CUDA is available!  Training on GPU ...')

# нам необходима версия pillow  5.3.0
# удалим старую версию и установим новую
!pip uninstall -y Pillow
!pip install Pillow==5.3.0
import PIL
print(PIL.PILLOW_VERSION)
# здесь должна быть версия 5.3.0. если это не так перехгрузите данный ноутбук:
# Menu > Runtime > Restart Runtime

from google.colab import drive
drive.mount('/content/gdrive/')

!unzip /content/gdrive/MyDrive/Course_stepic_NN/Classification_picture/Home_work/journey-springfield.zip -d journey-springfield

!ls journey-springfield

!nvidia-smi
import torch
torch.cuda.is_available()

"""В нашем тесте будет 990 картнок, для которых вам будет необходимо предсказать класс."""

!pip install https://github.com/CellProfiling/HPA-Cell-Segmentation/archive/master.zip # Без этого ниже код не заработает 
# Тут перезапустить

# Commented out IPython magic to ensure Python compatibility.
import pickle
import numpy as np
from skimage import io

from tqdm import tqdm, tqdm_notebook
from PIL import Image
from pathlib import Path
import torch

from torchvision import transforms
from multiprocessing.pool import ThreadPool
from sklearn.preprocessing import LabelEncoder
from torch.utils.data import Dataset, DataLoader
import torch.nn as nn

from matplotlib import colors, pyplot as plt
# %matplotlib inline

# в sklearn не все гладко, чтобы в colab удобно выводить картинки 
# мы будем игнорировать warnings
import warnings
warnings.filterwarnings(action='ignore', category=DeprecationWarning)

"""# Baseline model"""

# разные режимы датасета 
DATA_MODES = ['train', 'val', 'test']
# все изображения будут масштабированы к размеру 224x224 px
RESCALE_SIZE = 224
# работаем на видеокарте
DEVICE = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")

"""https://jhui.github.io/2018/02/09/PyTorch-Data-loading-preprocess_torchvision/

Ниже мы исспользуем враппер над датасетом для удобной работы. Вам стоит понимать, что происходит с LabelEncoder и  с torch.Transformation. 

ToTensor конвертирует  PIL Image с параметрами в диапазоне [0, 255] (как все пиксели) в FloatTensor размера (C x H x W) [0,1] , затем производится масштабирование:
$input = \frac{input - \mu}{\text{standard deviation}} $, <br>       константы - средние и дисперсии по каналам на основе ImageNet


Стоит также отметить, что мы переопределяем метод __getitem__ для удобства работы с данной структурой данных.
 Также используется LabelEncoder для преобразования строковых меток классов в id и обратно. В описании датасета указано, что картинки разного размера, так как брались напрямую с видео, поэтому следуем привести их к одному размер (это делает метод  _prepare_sample)
"""

class SimpsonsDataset(Dataset):
    """
    Датасет с картинками, который паралельно подгружает их из папок
    производит скалирование и превращение в торчевые тензоры
    """
    def __init__(self, files, mode):
        super().__init__()
        # список файлов для загрузки
        self.files = sorted(files)
        # режим работы
        self.mode = mode

        if self.mode not in DATA_MODES:
            print(f"{self.mode} is not correct; correct modes: {DATA_MODES}")
            raise NameError

        self.len_ = len(self.files)
     
        self.label_encoder = LabelEncoder()

        if self.mode != 'test':
            self.labels = [path.parent.name for path in self.files]
            self.label_encoder.fit(self.labels)

            with open('label_encoder.pkl', 'wb') as le_dump_file:
                  pickle.dump(self.label_encoder, le_dump_file)
                      
    def __len__(self):
        return self.len_
      
    def load_sample(self, file):
        image = Image.open(file)
        image.load()
        return image
  
    def __getitem__(self, index):
        # для преобразования изображений в тензоры PyTorch и нормализации входа
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) 
        ])
        
        x = self.load_sample(self.files[index])
        x = self._prepare_sample(x)
        x = np.array(x / 255, dtype='float32')
        x = transform(x)
        if self.mode == 'test':
            return x
        else:
            label = self.labels[index]
            label_id = self.label_encoder.transform([label])
            y = label_id.item()
            return x, y
        
    def _prepare_sample(self, image):
        image = image.resize((RESCALE_SIZE, RESCALE_SIZE))
        return np.array(image)

def imshow(inp, title=None, plt_ax=plt, default=False):
    """Imshow для тензоров"""
    inp = inp.numpy().transpose((1, 2, 0))
    mean = np.array([0.485, 0.456, 0.406])
    std = np.array([0.229, 0.224, 0.225])
    inp = std * inp + mean
    inp = np.clip(inp, 0, 1)
    plt_ax.imshow(inp)
    if title is not None:
        plt_ax.set_title(title)
    plt_ax.grid(False)

TRAIN_DIR = Path('journey-springfield/train')
TEST_DIR = Path('journey-springfield/testset')

train_val_files = sorted(list(TRAIN_DIR.rglob('*.jpg')))
test_files = sorted(list(TEST_DIR.rglob('*.jpg')))

from sklearn.model_selection import train_test_split

train_val_labels = [path.parent.name for path in train_val_files]
train_files, val_files = train_test_split(train_val_files, test_size=0.25, \
                                          stratify=train_val_labels)

val_dataset = SimpsonsDataset(val_files, mode='val')

# uncomment if you have problem with pillow
# def register_extension(id, extension): Image.EXTENSION[extension.lower()] = id.upper()
# Image.register_extension = register_extension
# def register_extensions(id, extensions): 
#     for extension in extensions: register_extension(id, extension)
# Image.register_extensions = register_extensions

"""Давайте посмотрим на наших героев внутри датасета."""

fig, ax = plt.subplots(nrows=3, ncols=3,figsize=(8, 8), \
                        sharey=True, sharex=True) # sharey=True - Убирает лишние метки по оси x
for fig_x in ax.flatten():                        # sharex=True - Убирает лишние метки по оси y
    random_characters = int(np.random.uniform(0,1000))
    im_val, label = val_dataset[random_characters]
    img_label = " ".join(map(lambda x: x.capitalize(),\
                val_dataset.label_encoder.inverse_transform([label])[0].split('_')))
    imshow(im_val.data.cpu(), \
          title=img_label,plt_ax=fig_x)

"""Можете добавить ваши любимые сцены и классифицировать их. (веселые результаты можно кидать в чат)

### Построение нейросети

Данная архитектура будет очень простой и нужна для того, чтобы установить базовое понимание и получить простенький сабмит на Kaggle

<!-- Здесь вам предлагается дописать сверточную сеть глубины 4/5.  -->

*Описание слоев*:



1. размерность входа: 3x224x224 
2.размерности после слоя:  8x111x111
3. 16x54x54
4. 32x26x26
5. 64x12x12
6. выход: 96x5x5
"""

# Очень простая сеть
class SimpleCnn(nn.Module):
  
    def __init__(self, n_classes):
        super().__init__()
        self.conv1 = nn.Sequential(
            nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2)
        )
        self.conv2 = nn.Sequential(
            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2)
        )
        self.conv3 = nn.Sequential(
            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2)
        )
        self.conv4 = nn.Sequential(
            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2)
        )
        self.conv5 = nn.Sequential(
            nn.Conv2d(in_channels=64, out_channels=96, kernel_size=3),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2)
        )
        
        self.out = nn.Linear(96 * 5 * 5, n_classes)
  
  
    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        x = self.conv4(x)
        x = self.conv5(x)

        x = x.view(x.size(0), -1)
        logits = self.out(x)
        return logits

def fit_epoch(model, train_loader, criterion, optimizer):
    running_loss = 0.0
    running_corrects = 0
    processed_data = 0
  
    for inputs, labels in train_loader:
        model.train()
        inputs = inputs.to(DEVICE)
        labels = labels.to(DEVICE)
        optimizer.zero_grad()

        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        preds = torch.argmax(outputs, 1)
        running_loss += loss.item() * inputs.size(0)
        running_corrects += torch.sum(preds == labels.data)
        processed_data += inputs.size(0)
              
    train_loss = running_loss / processed_data
    train_acc = running_corrects.cpu().numpy() / processed_data
    return train_loss, train_acc

def eval_epoch(model, val_loader, criterion):
    model.eval()
    running_loss = 0.0
    running_corrects = 0
    processed_size = 0

    for inputs, labels in val_loader:
        inputs = inputs.to(DEVICE)
        labels = labels.to(DEVICE)

        with torch.set_grad_enabled(False):
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            preds = torch.argmax(outputs, 1)

        running_loss += loss.item() * inputs.size(0)
        running_corrects += torch.sum(preds == labels.data)
        processed_size += inputs.size(0)
    val_loss = running_loss / processed_size
    val_acc = running_corrects.double() / processed_size
    return val_loss, val_acc

def train(train_files, val_files, model, epochs, batch_size):
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

    history = []
    log_template = "\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \
    val_loss {v_loss:0.4f} train_acc {t_acc:0.4f} val_acc {v_acc:0.4f}"

    with tqdm(desc="epoch", total=epochs) as pbar_outer:
        opt = torch.optim.Adam(model.parameters())
        criterion = nn.CrossEntropyLoss()

        for epoch in range(epochs):
            train_loss, train_acc = fit_epoch(model, train_loader, criterion, opt)
            print("loss", train_loss)
            
            val_loss, val_acc = eval_epoch(model, val_loader, criterion)
            history.append((train_loss, train_acc, val_loss, val_acc))
            
            pbar_outer.update(1)
            tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss,\
                                           v_loss=val_loss, t_acc=train_acc, v_acc=val_acc))
            
    return history

def predict(model, test_loader):
    with torch.no_grad():
        logits = []
    
        for inputs in test_loader:
            inputs = inputs.to(DEVICE)
            model.eval()
            outputs = model(inputs).cpu()
            logits.append(outputs)
            
    probs = nn.functional.softmax(torch.cat(logits), dim=-1).numpy()
    return probs

n_classes = len(np.unique(train_val_labels))
simple_cnn = SimpleCnn(n_classes).to(DEVICE)
print("we will classify :{}".format(n_classes))
print(simple_cnn)

"""Запустим обучение сети."""

if val_dataset is None:
    val_dataset = SimpsonsDataset(val_files, mode='val')
    
train_dataset = SimpsonsDataset(train_files, mode='train')

history = train(train_dataset, val_dataset, model=simple_cnn, epochs=2, batch_size=64)

"""Построим кривые обучения"""

loss, acc, val_loss, val_acc = zip(*history)

plt.figure(figsize=(15, 9))
plt.plot(loss, label="train_loss")
plt.plot(val_loss, label="val_loss")
plt.legend(loc='best')
plt.xlabel("epochs")
plt.ylabel("loss")
plt.show()

"""### Ну и что теперь со всем этим делать?

![alt text](https://www.indiewire.com/wp-content/uploads/2014/08/the-simpsons.jpg)
"""

def predict_one_sample(model, inputs, device=DEVICE):
    """Предсказание, для одной картинки"""
    with torch.no_grad():
        inputs = inputs.to(device)
        model.eval()
        logit = model(inputs).cpu()
        probs = torch.nn.functional.softmax(logit, dim=-1).numpy()
    return probs

random_characters = int(np.random.uniform(0,1000))
ex_img, true_label = val_dataset[random_characters]
probs_im = predict_one_sample(simple_cnn, ex_img.unsqueeze(0))

idxs = list(map(int, np.random.uniform(0,1000, 20)))
imgs = [val_dataset[id][0].unsqueeze(0) for id in idxs]

probs_ims = predict(simple_cnn, imgs)

label_encoder = pickle.load(open("label_encoder.pkl", 'rb'))

y_pred = np.argmax(probs_ims,-1)

actual_labels = [val_dataset[id][1] for id in idxs]

preds_class = [label_encoder.classes_[i] for i in y_pred]

"""Обратите внимание, что метрика, которую необходимо оптимизировать в конкурсе --- f1-score. Вычислим целевую метрику на валидационной выборке."""

actual_labels
act_labels_prvd = [label_encoder.classes_[i] for i in actual_labels]

act_labels_prvd

"""Сделаем классную визуализацию,  чтобы посмотреть насколько сеть уверена в своих ответах. Можете исспользовать это, чтобы отлаживать правильность вывода."""

import matplotlib.patches as patches
from matplotlib.font_manager import FontProperties

fig, ax = plt.subplots(nrows=3, ncols=3,figsize=(12, 12), \
                        sharey=True, sharex=True)
for fig_x in ax.flatten():
    random_characters = int(np.random.uniform(0,1000))
    im_val, label = val_dataset[random_characters]
    img_label = " ".join(map(lambda x: x.capitalize(),\
                val_dataset.label_encoder.inverse_transform([label])[0].split('_')))
   
     

    imshow(im_val.data.cpu(), \
          title=img_label,plt_ax=fig_x)
    
    actual_text = "Actual : {}".format(img_label)
            
    fig_x.add_patch(patches.Rectangle((0, 53),86,35,color='white'))
    font0 = FontProperties()
    font = font0.copy()
    font.set_family("fantasy")
    prob_pred = predict_one_sample(simple_cnn, im_val.unsqueeze(0))
    predicted_proba = np.max(prob_pred)*100
    y_pred = np.argmax(prob_pred)
    
    predicted_label = label_encoder.classes_[y_pred]
    predicted_label = predicted_label[:len(predicted_label)//2] + '\n' + predicted_label[len(predicted_label)//2:]
    predicted_text = "{} : {:.0f}%".format(predicted_label,predicted_proba)
            
    fig_x.text(1, 59, predicted_text , horizontalalignment='left', fontproperties=font,
                    verticalalignment='top',fontsize=8, color='black',fontweight='bold')

"""Попробуйте найти те классы, которые сеть не смогла расспознать. Изучите данную проблему, это понадобится в дальнейшем.

### Submit на Kaggle

![alt text](https://i.redd.it/nuaphfioz0211.jpg)

## Приключение?

А теперь самое интересное, мы сделали простенькую сверточную сеть и смогли отправить сабмит, но получившийся скор нас явно не устраивает. Надо с этим что-то сделать. 

Несколько срочныйх улучшейни для нашей сети, которые наверняка пришли Вам в голову: 


*   Учим дольше и изменяем гиперпараметры сети
*  learning rate, batch size, нормализация картинки и вот это всё
*   Кто же так строит нейронные сети? А где пулинги и батч нормы? Надо добавлять
*  Ну разве Адам наше все? [adamW](https://www.fast.ai/2018/07/02/adam-weight-decay/) для практика, [статейка для любителей](https://openreview.net/pdf?id=ryQu7f-RZ) (очень хороший анализ), [наши ](https://github.com/MichaelKonobeev/adashift/) эксперименты для заинтересованных.

* Ну разве это deep learning? Вот ResNet и Inception, которые можно зафайнтьюнить под наши данные, вот это я понимаю (можно и обучить в колабе, а можно и [готовые](https://github.com/Cadene/pretrained-models.pytorch) скачать).

* Данных не очень много, можно их аугументировать и  доучититься на новом датасете ( который уже будет состоять из, как  пример аугументации, перевернутых изображений)

* Стоит подумать об ансамблях


Надеюсь, что у Вас получится!

![alt text](https://pbs.twimg.com/profile_images/798904974986113024/adcQiVdV.jpg)

Далее я попробую улучшить модель с помощью аугментации и различных преобразований

# Improving models

Здесь будут написаны общие функции которые будут использовать в дальнейшем

## Общие функции

- Функция для расчета метрики f1-score различными способами
"""

from sklearn.metrics import f1_score

def get_f1_score(act_labels, preds_label):

    f1_micro = f1_score(act_labels_prvd, preds_label, average='micro')
    f1_macro = f1_score(act_labels_prvd, preds_label, average='macro')
    f1_weight = f1_score(act_labels_prvd, preds_label, average='weighted')

    print(f'f1 score(micro) = {round(f1_micro, 4)}')
    print(f'f1 score(macro) = {round(f1_macro, 4)}')
    print(f'f1 score(weight) = {round(f1_weight, 4)}')

"""- Функция для предсказания на валидационной выборке (для расчета f1-score)"""

def val_predict(model, val_loader):
    with torch.no_grad():
        logits = []
    
        for inputs in val_loader:
            inputs = inputs[0]
            inputs = inputs.to(DEVICE)
            model.eval()
            outputs = model(inputs).cpu()
            logits.append(outputs)
            
    probs = nn.functional.softmax(torch.cat(logits), dim=-1).numpy()
    return probs

"""- Функция для получения предсказаний"""

def get_test_filenames(dataset=None,  
                       cnn=None,
                       f_test_files=None, 
                       batch_size=128,
                       f_label_encoder=None):

    if f_label_encoder is None:
        label_encoder = pickle.load(open("label_encoder.pkl", 'rb'))

    if f_test_files is None:
        test_files = sorted(list(TEST_DIR.rglob('*.jpg')))

    test_dataset = AugmentSimpsonsDataset(test_files, mode="test")
    test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)
    probs = predict(cnn, test_loader)

    preds = label_encoder.inverse_transform(np.argmax(probs, axis=1))
    test_filenames = [path.name for path in test_dataset.files]

    return preds, test_filenames

"""- Функция для сохранения результатов"""

import pandas as pd

def save_submit(test_filenames=None, 
                preds=None,
                read_path='/content/journey-springfield/sample_submission.csv', 
                save_path=None):

    my_submit = pd.read_csv(read_path)
    my_submit = pd.DataFrame({'Id': test_filenames, 'Expected': preds})
    my_submit.to_csv(save_path, index=False)

    return my_submit

"""## Аугментации

### Примененим горзинт_аугмнт

#### Обучение и предикт

- Переопределим класс
"""

class AugmentSimpsonsDataset(SimpsonsDataset):
    def __init__(self, files, mode, augmt_tfs=None):
        super().__init__(files, mode)
        self.augmt_tfs = augmt_tfs

    def __getitem__(self, index):

        if self.mode == 'train':
            transform = self.augmt_tfs

        if self.mode == 'val' or self.mode == 'test':
            transform = transforms.Compose([
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) 
            ])
        
        x = self.load_sample(self.files[index])
        x = self._prepare_sample(x)
        x = np.array(x / 255, dtype='float32')
        x = transform(x)

        if self.mode == 'test':
            return x
        else:
            label = self.labels[index]
            label_id = self.label_encoder.transform([label])
            y = label_id.item()
            return x, y

"""- Разделим на тестовую и трановую выборку"""

from sklearn.model_selection import train_test_split

train_val_labels = [path.parent.name for path in train_val_files]
train_files, val_files = train_test_split(train_val_files, test_size=0.25, \
                                          stratify=train_val_labels)

"""- Зададим transforms и датасеты"""

from torchvision import transforms

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.RandomHorizontalFlip(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) 
])

train_dataset = AugmentSimpsonsDataset(train_files, mode='train', augmt_tfs=transform)
val_dataset = AugmentSimpsonsDataset(val_files, mode='val')

"""- Обучение"""

n_classes = len(np.unique(train_val_labels))
simple_cnn = SimpleCnn(n_classes).to(DEVICE)
history = train(train_dataset, val_dataset, model=simple_cnn, epochs=8, batch_size=128)

"""- Визуализируем лосы"""

loss, acc, val_loss, val_acc = zip(*history)
plt.figure(figsize=(15, 9))
plt.plot(loss, label="train_loss")
plt.plot(val_loss, label="val_loss")
plt.legend(loc='best')
plt.xlabel("epochs")
plt.ylabel("loss")
plt.show()

label_encoder = pickle.load(open("label_encoder.pkl", 'rb'))

val_dataset = AugmentSimpsonsDataset(val_files, mode="val")
val_loader = DataLoader(val_dataset, shuffle=False, batch_size=256)
probs = val_predict(simple_cnn, val_loader)
label_preds = label_encoder.inverse_transform(np.argmax(probs, axis=1))

actual_labels = [val_dataset[id][1] for id in range(len(val_dataset))]
act_labels_prvd = [label_encoder.classes_[i] for i in actual_labels]

"""- Сделаем предикт на тестовых данных"""

preds, test_filenames = get_test_filenames(dataset=AugmentSimpsonsDataset, cnn=simple_cnn, batch_size=128)

"""- Сохраним предсказания"""

save_path = '/content/gdrive/MyDrive/Course_stepic_NN/Classification_picture/Home_work/simple_cnn_aygment_gorizont.csv'

save_submit(test_filenames=test_filenames, preds=preds, save_path=save_path)

"""#### Score

![изображение.png](data:image/png;base64,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)

### Обычный_проход + Горизнт_аугментация

#### Обучение и предикт
"""

from torchvision import transforms

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.RandomHorizontalFlip(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) 
])

n_classes = len(np.unique(train_val_labels))
simple_cnn = SimpleCnn(n_classes).to(DEVICE)

val_dataset = SimpsonsDataset(val_files, mode='val')
train_dataset = SimpsonsDataset(train_files, mode='train')
history = train(train_dataset, val_dataset, model=simple_cnn, epochs=4, batch_size=128)

train_dataset = AugmentSimpsonsDataset(train_files, mode='train', augmt_tfs=transform)
val_dataset = AugmentSimpsonsDataset(val_files, mode='val')
history = train(train_dataset, val_dataset, model=simple_cnn, epochs=4, batch_size=128)

"""- Визуализируем лосы"""

loss, acc, val_loss, val_acc = zip(*history)
plt.figure(figsize=(15, 9))
plt.plot(loss, label="train_loss")
plt.plot(val_loss, label="val_loss")
plt.legend(loc='best')
plt.xlabel("epochs")
plt.ylabel("loss")
plt.show()

"""- Сделаем предикт на валидационных данных для расчета f1-score"""

label_encoder = pickle.load(open("label_encoder.pkl", 'rb'))

val_dataset = AugmentSimpsonsDataset(val_files, mode="val")
val_loader = DataLoader(val_dataset, shuffle=False, batch_size=256)
probs = val_predict(simple_cnn, val_loader)
label_preds = label_encoder.inverse_transform(np.argmax(probs, axis=1))

actual_labels = [val_dataset[id][1] for id in range(len(val_dataset))]
act_labels_prvd = [label_encoder.classes_[i] for i in actual_labels]

"""- Рассчитаем f1-score"""

get_f1_score(act_labels_prvd, label_preds)

"""- Сделаем предикт на тестовых данных"""

preds, test_filenames = get_test_filenames(dataset=AugmentSimpsonsDataset, cnn=simple_cnn, batch_size=128)

"""- Сохраним предсказания"""

save_path = '/content/gdrive/MyDrive/Course_stepic_NN/Classification_picture/Home_work/simple_cnn_usual_approach_aygment_gorizont.csv'

save_submit(test_filenames=test_filenames, preds=preds, save_path=save_path)

"""#### Score

![изображение.png](data:image/png;base64,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)

### Обычный_проход + Горизнт_аугментация+ lr

- Переопределим функцию train, чтобы можно было в параметрах указать оптимизатор
"""

def train(train_files, val_files, model, epochs, batch_size, optimizer):
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

    history = []
    log_template = "\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \
    val_loss {v_loss:0.4f} train_acc {t_acc:0.4f} val_acc {v_acc:0.4f}"

    with tqdm(desc="epoch", total=epochs) as pbar_outer:
        opt = optimizer
        criterion = nn.CrossEntropyLoss()

        for epoch in range(epochs):
            train_loss, train_acc = fit_epoch(model, train_loader, criterion, opt)
            print("loss", train_loss)
            
            val_loss, val_acc = eval_epoch(model, val_loader, criterion)
            history.append((train_loss, train_acc, val_loss, val_acc))
            
            pbar_outer.update(1)
            tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss,\
                                           v_loss=val_loss, t_acc=train_acc, v_acc=val_acc))

    return history

"""#### Обучение и предикт"""

from torchvision import transforms

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.RandomHorizontalFlip(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) 
])

def train(train_files, val_files, model, epochs, batch_size, mdl_opt):
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

    history = []
    log_template = "\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \
    val_loss {v_loss:0.4f} train_acc {t_acc:0.4f} val_acc {v_acc:0.4f}"

    with tqdm(desc="epoch", total=epochs) as pbar_outer:
        opt = mdl_opt
        criterion = nn.CrossEntropyLoss()

        for epoch in range(epochs):
            train_loss, train_acc = fit_epoch(model, train_loader, criterion, opt)
            print("loss", train_loss)
            
            val_loss, val_acc = eval_epoch(model, val_loader, criterion)
            history.append((train_loss, train_acc, val_loss, val_acc))
            
            pbar_outer.update(1)
            tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss,\
                                           v_loss=val_loss, t_acc=train_acc, v_acc=val_acc))
    
    return history

n_classes = len(np.unique(train_val_labels))
simple_cnn = SimpleCnn(n_classes).to(DEVICE)

val_dataset = SimpsonsDataset(val_files, mode='val')
train_dataset = SimpsonsDataset(train_files, mode='train')

optimizer = torch.optim.Adam(simple_cnn.parameters(), lr=3*0.001) #, lr=1e-2

history = train(train_dataset, val_dataset, model=simple_cnn, epochs=4, batch_size=128, mdl_opt=optimizer)

train_dataset = AugmentSimpsonsDataset(train_files, mode='train', augmt_tfs=transform)
val_dataset = AugmentSimpsonsDataset(val_files, mode='val')
history = train(train_dataset, val_dataset, model=simple_cnn, epochs=4, batch_size=128, mdl_opt=optimizer)

"""### Обычный_проход + Горизнт_аугментация + sheduler

#### Обучение и предикт
"""

def train(train_files, val_files, model, epochs, batch_size, mdl_opt, mdl_sheduler):
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

    history = []
    log_template = "\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \
    val_loss {v_loss:0.4f} train_acc {t_acc:0.4f} val_acc {v_acc:0.4f}"

    with tqdm(desc="epoch", total=epochs) as pbar_outer:
        opt = mdl_opt
        criterion = nn.CrossEntropyLoss()

        for epoch in range(epochs):
            train_loss, train_acc = fit_epoch(model, train_loader, criterion, opt, mdl_sheduler)
            print("loss", train_loss)
            
            val_loss, val_acc = eval_epoch(model, val_loader, criterion)
            history.append((train_loss, train_acc, val_loss, val_acc))
            
            pbar_outer.update(1)
            tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss,\
                                           v_loss=val_loss, t_acc=train_acc, v_acc=val_acc))
            
    return history

def fit_epoch(model, train_loader, criterion, optimizer, mdl_sheduler=None):
    running_loss = 0.0
    running_corrects = 0
    processed_data = 0
  
    for inputs, labels in train_loader:
        model.train()
        inputs = inputs.to(DEVICE)
        labels = labels.to(DEVICE)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        preds = torch.argmax(outputs, 1)
        running_loss += loss.item() * inputs.size(0)
        running_corrects += torch.sum(preds == labels.data)
        processed_data += inputs.size(0)

    mdl_sheduler.step()

    train_loss = running_loss / processed_data
    train_acc = running_corrects.cpu().numpy() / processed_data
    
    return train_loss, train_acc

from torchvision import transforms

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.RandomHorizontalFlip(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) 
])

n_classes = len(np.unique(train_val_labels))
simple_cnn = SimpleCnn(n_classes).to(DEVICE)

from torch.optim import lr_scheduler

val_dataset = SimpsonsDataset(val_files, mode='val')
train_dataset = SimpsonsDataset(train_files, mode='train')

optimizer = torch.optim.Adam(simple_cnn.parameters(), lr=1e-3)
scheduler = lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5)

history = train(train_dataset, val_dataset, model=simple_cnn, epochs=3, batch_size=128, mdl_opt=optimizer, mdl_sheduler=scheduler)

train_dataset = AugmentSimpsonsDataset(train_files, mode='train', augmt_tfs=transform)
val_dataset = AugmentSimpsonsDataset(val_files, mode='val')

optimizer = torch.optim.Adam(simple_cnn.parameters(), lr=1e-3)
scheduler = lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5)

history = train(train_dataset, val_dataset, model=simple_cnn, epochs=4, batch_size=128, mdl_opt=optimizer, mdl_sheduler=scheduler)

"""- Сделаем предикт на валидационных данных для расчета f1-score"""

label_encoder = pickle.load(open("label_encoder.pkl", 'rb'))

val_dataset = AugmentSimpsonsDataset(val_files, mode="val")
val_loader = DataLoader(val_dataset, shuffle=False, batch_size=256)
probs = val_predict(simple_cnn, val_loader)
label_preds = label_encoder.inverse_transform(np.argmax(probs, axis=1))

actual_labels = [val_dataset[id][1] for id in range(len(val_dataset))]
act_labels_prvd = [label_encoder.classes_[i] for i in actual_labels]

"""- Рассчитаем f1-score"""

get_f1_score(act_labels_prvd, label_preds)

"""Как мы видим это нам не помогло

Попробуем теперь воспользовать сетью resnet

# Resnet

## Resnet101

### Обучение и предикт
"""

from torchvision import models 
import torchvision

models_resnet101 = models.resnet101(pretrained=True)
models_resnet101

num_features = 2048
n_classes = len(np.unique(train_val_labels))
models_resnet101.fc = nn.Linear(num_features, n_classes, bias=True)

"""Обучать будем все слои с разным lr"""

optimizer = torch.optim.AdamW( params=[
        {"params": models_resnet101.conv1.parameters(), "lr": 1e-6},
        {"params": models_resnet101.bn1.parameters(), "lr": 1e-6},
        {"params": models_resnet101.maxpool.parameters(), "lr": 1e-6},
        {"params": models_resnet101.layer3.parameters(), "lr": 1e-6},
        {"params": models_resnet101.layer2.parameters(), "lr": 1e-5},
        {"params": models_resnet101.layer1.parameters(), "lr": 1e-4},
        {"params": models_resnet101.fc.parameters()},
    ], 
    lr=1e-3, amsgrad=True
)

models_resnet101 = models_resnet101.cuda()

for param in models_resnet101.parameters():
    param.requires_grad = True

"""Пройдёмся по 5-ти эпохам"""

from torch.optim import lr_scheduler


scheduler = lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.5)

val_dataset = SimpsonsDataset(val_files, mode='val')
train_dataset = SimpsonsDataset(train_files, mode='train')

history = train(train_dataset, val_dataset, model=models_resnet101, epochs=5, batch_size=64, mdl_opt=optimizer, mdl_sheduler=scheduler)

# torch.save(models_resnet101.state_dict(), '/content/gdrive/MyDrive/Course_stepic_NN/Classification_picture/Home_work/Models/models_resnet101_AdamW_Aug_e5.pth')

models_resnet101.load_state_dict(torch.load('/content/gdrive/MyDrive/Course_stepic_NN/Classification_picture/Home_work/Models/models_resnet101_AdamW_Aug_e5.pth'))

loss, acc, val_loss, val_acc = zip(*history)
plt.figure(figsize=(15, 9))
plt.plot(loss, label="train_loss")
plt.plot(val_loss, label="val_loss")
plt.legend(loc='best')
plt.xlabel("epochs")
plt.ylabel("loss")
plt.show()

"""### Добавим аугментации"""

RESCALE_SIZE = 256

class AugmentSimpsonsDataset(SimpsonsDataset):
    def __init__(self, files, mode, augmt_tfs=None):
        super().__init__(files, mode)
        self.augmt_tfs = augmt_tfs

    def __getitem__(self, index):

        if self.mode == 'train':
            transform = self.augmt_tfs

        if self.mode == 'val' or self.mode == 'test':
            transform = transforms.Compose([
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) 
            ])
        
        x = self.load_sample(self.files[index])
        x = self._prepare_sample(x)
        x = np.array(x / 255, dtype='float32')
        x = transform(x)

        if self.mode == 'test':
            return x
        else:
            label = self.labels[index]
            label_id = self.label_encoder.transform([label])
            y = label_id.item()
            return x, y

from torchvision import transforms

transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.RandomRotation(degrees=(-10, 10), expand=True),
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.RandomResizedCrop(244),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) 
])

optimizer = torch.optim.AdamW( params=[
        {"params": models_resnet101.conv1.parameters(), "lr": 1e-6},
        {"params": models_resnet101.bn1.parameters(), "lr": 1e-6},
        {"params": models_resnet101.maxpool.parameters(), "lr": 1e-6},
        {"params": models_resnet101.layer3.parameters(), "lr": 1e-6},
        {"params": models_resnet101.layer2.parameters(), "lr": 1e-5},
        {"params": models_resnet101.layer1.parameters(), "lr": 1e-4},
        {"params": models_resnet101.fc.parameters()},
    ], 
    lr=1e-3, amsgrad=True
)

from torch.optim import lr_scheduler

scheduler = lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.5)

train_dataset = AugmentSimpsonsDataset(train_files, mode='train', augmt_tfs=transform)
val_dataset = AugmentSimpsonsDataset(val_files, mode='val')

history = train(train_dataset, val_dataset, model=models_resnet101, epochs=5, batch_size=64, mdl_opt=optimizer, mdl_sheduler=scheduler)

torch.save(models_resnet101.state_dict(), '/content/gdrive/MyDrive/Course_stepic_NN/Classification_picture/Home_work/Models/models_resnet101_AdamW_Aug_e10.pth')

"""- Визуализируем лосы"""

loss, acc, val_loss, val_acc = zip(*history)
plt.figure(figsize=(15, 9))
plt.plot(loss, label="train_loss")
plt.plot(val_loss, label="val_loss")
plt.legend(loc='best')
plt.xlabel("epochs")
plt.ylabel("loss")
plt.show()

"""- Сделаем предикт на валидационных данных для расчета f1-score"""

label_encoder = pickle.load(open("label_encoder.pkl", 'rb'))

val_dataset = AugmentSimpsonsDataset(val_files, mode="val")
val_loader = DataLoader(val_dataset, shuffle=False, batch_size=256)
probs = val_predict(models_resnet101, val_loader)
label_preds = label_encoder.inverse_transform(np.argmax(probs, axis=1))

actual_labels = [val_dataset[id][1] for id in range(len(val_dataset))]
act_labels_prvd = [label_encoder.classes_[i] for i in actual_labels]

"""- Рассчитаем f1-score"""

get_f1_score(act_labels_prvd, label_preds)

"""- Сделаем предикт на тестовых данных"""

preds, test_filenames = get_test_filenames(dataset=AugmentSimpsonsDataset, cnn=models_resnet101, batch_size=64)

"""- Сохраним предсказания"""

save_path = '/content/gdrive/MyDrive/Course_stepic_NN/Classification_picture/Home_work/resnet101_e10.csv'

save_submit(test_filenames=test_filenames, preds=preds, save_path=save_path)

"""### Score

## Resnet101_баланс_классов

В датасете классы несбалансированы поэтому попробуем сбалансировать
"""

from torchvision import models 
import torchvision

models_resnet101 = models.resnet101(pretrained=True)

num_features = 2048
n_classes = len(np.unique(train_val_labels))
models_resnet101.fc = nn.Linear(num_features, n_classes, bias=True)

optimizer = torch.optim.AdamW( params=[
        {"params": models_resnet101.conv1.parameters(), "lr": 1e-6},
        {"params": models_resnet101.bn1.parameters(), "lr": 1e-6},
        {"params": models_resnet101.maxpool.parameters(), "lr": 1e-6},
        {"params": models_resnet101.layer3.parameters(), "lr": 1e-6},
        {"params": models_resnet101.layer2.parameters(), "lr": 1e-5},
        {"params": models_resnet101.layer1.parameters(), "lr": 1e-4},
        {"params": models_resnet101.fc.parameters()},
    ], 
    lr=1e-3, amsgrad=True
)

models_resnet101 = models_resnet101.cuda()

for param in models_resnet101.parameters():
    param.requires_grad = True

models_resnet101.load_state_dict(torch.load('/content/gdrive/MyDrive/Course_stepic_NN/Classification_picture/Home_work/Models/models_resnet101_AdamW_Aug_e10.pth'))

class AugmentSimpsonsDataset(SimpsonsDataset):
    def __init__(self, files, mode, augmt_tfs=None):
        super().__init__(files, mode)
        self.augmt_tfs = augmt_tfs

    def __getitem__(self, index):

        if self.mode == 'train':
            transform = self.augmt_tfs

        if self.mode == 'val' or self.mode == 'test':
            transform = transforms.Compose([
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) 
            ])
        
        x = self.load_sample(self.files[index])
        x = self._prepare_sample(x)
        x = np.array(x / 255, dtype='float32')
        x = transform(x)

        if self.mode == 'test':
            return x
        else:
            label = self.labels[index]
            label_id = self.label_encoder.transform([label])
            y = label_id.item()
            return x, y

from torch.utils.data.sampler import SubsetRandomSampler, WeightedRandomSampler

val_dataset = AugmentSimpsonsDataset(val_files, mode='val')
train_dataset = AugmentSimpsonsDataset(train_files, mode='train')


train_dataset = SimpsonsDataset(val_files, mode='train')
# val_dataset = SimpsonsDataset(val_files, mode='val')
train_label = [train_dataset[id][1] for id in range(len(train_dataset))]
# val_label = [val_dataset[id][1] for id in range(len(val_dataset))]
# labels = np.array(train_label + val_label)
labels = np.array(train_label)
class_sample_count = np.array([len(np.where(labels==t)[0]) for t in np.unique(labels)])
weight = 1. / class_sample_count
samples_weight = np.array([weight[t] for t in labels])
samples_weight = torch.from_numpy(samples_weight)

def train(train_files, val_files, model, epochs, batch_size, mdl_opt, mdl_sheduler):
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

    history = []
    log_template = "\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \
    val_loss {v_loss:0.4f} train_acc {t_acc:0.4f} val_acc {v_acc:0.4f}"

    with tqdm(desc="epoch", total=epochs) as pbar_outer:
        opt = mdl_opt
        criterion = nn.CrossEntropyLoss()

        for epoch in range(epochs):
            train_loss, train_acc = fit_epoch(model, train_loader, criterion, opt, mdl_sheduler)
            print("loss", train_loss)
            
            val_loss, val_acc = eval_epoch(model, val_loader, criterion)
            history.append((train_loss, train_acc, val_loss, val_acc))
            
            pbar_outer.update(1)
            tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss,\
                                           v_loss=val_loss, t_acc=train_acc, v_acc=val_acc))
            
    return history

def fit_epoch(model, train_loader, criterion, optimizer, mdl_sheduler=None):
    running_loss = 0.0
    running_corrects = 0
    processed_data = 0
  
    for inputs, labels in train_loader:
        model.train()
        inputs = inputs.to(DEVICE)
        labels = labels.to(DEVICE)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        preds = torch.argmax(outputs, 1)
        running_loss += loss.item() * inputs.size(0)
        running_corrects += torch.sum(preds == labels.data)
        processed_data += inputs.size(0)

    mdl_sheduler.step()

    train_loss = running_loss / processed_data
    train_acc = running_corrects.cpu().numpy() / processed_data
    
    return train_loss, train_acc

from torchvision import transforms

transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.RandomRotation(degrees=(-10, 10), expand=True),
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.RandomResizedCrop(244),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) 
])

from torch.optim import lr_scheduler

scheduler = lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.5)

train_dataset = AugmentSimpsonsDataset(train_files, mode='train', augmt_tfs=transform)
val_dataset = AugmentSimpsonsDataset(val_files, mode='val')

history = train(train_dataset, val_dataset, model=models_resnet101, epochs=8, batch_size=64, mdl_opt=optimizer, mdl_sheduler=scheduler)

torch.save(models_resnet101.state_dict(), '/content/gdrive/MyDrive/Course_stepic_NN/Classification_picture/Home_work/Models/models_resnet101_18e.pth')

from torch.optim import lr_scheduler

scheduler = lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.5)

train_dataset = AugmentSimpsonsDataset(train_files, mode='train', augmt_tfs=transform)
val_dataset = AugmentSimpsonsDataset(val_files, mode='val')

history = train(train_dataset, val_dataset, model=models_resnet101, epochs=8, batch_size=64, mdl_opt=optimizer, mdl_sheduler=scheduler)

torch.save(models_resnet101.state_dict(), '/content/gdrive/MyDrive/Course_stepic_NN/Classification_picture/Home_work/Models/models_resnet101_26e.pth')

"""### ДОобучение"""

from torchvision import models 
import torchvision

models_resnet101 = models.resnet101(pretrained=True)

num_features = 2048
n_classes = len(np.unique(train_val_labels))
models_resnet101.fc = nn.Linear(num_features, n_classes, bias=True)

models_resnet101 = models_resnet101.cuda()

for param in models_resnet101.parameters():
    param.requires_grad = True

def train(train_files, val_files, model, epochs, batch_size, mdl_opt, mdl_sheduler):
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

    history = []
    log_template = "\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \
    val_loss {v_loss:0.4f} train_acc {t_acc:0.4f} val_acc {v_acc:0.4f}"

    with tqdm(desc="epoch", total=epochs) as pbar_outer:
        opt = mdl_opt
        criterion = nn.CrossEntropyLoss()

        for epoch in range(epochs):
            train_loss, train_acc = fit_epoch(model, train_loader, criterion, opt, mdl_sheduler)
            print("loss", train_loss)
            
            val_loss, val_acc = eval_epoch(model, val_loader, criterion)
            history.append((train_loss, train_acc, val_loss, val_acc))
            
            pbar_outer.update(1)
            tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss,\
                                           v_loss=val_loss, t_acc=train_acc, v_acc=val_acc))
            
    return history

def fit_epoch(model, train_loader, criterion, optimizer, mdl_sheduler=None):
    running_loss = 0.0
    running_corrects = 0
    processed_data = 0
  
    for inputs, labels in train_loader:
        model.train()
        inputs = inputs.to(DEVICE)
        labels = labels.to(DEVICE)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        preds = torch.argmax(outputs, 1)
        running_loss += loss.item() * inputs.size(0)
        running_corrects += torch.sum(preds == labels.data)
        processed_data += inputs.size(0)

    mdl_sheduler.step()

    train_loss = running_loss / processed_data
    train_acc = running_corrects.cpu().numpy() / processed_data
    
    return train_loss, train_acc

class AugmentSimpsonsDataset(SimpsonsDataset):
    def __init__(self, files, mode, augmt_tfs=None):
        super().__init__(files, mode)
        self.augmt_tfs = augmt_tfs

    def __getitem__(self, index):

        if self.mode == 'train':
            transform = self.augmt_tfs

        if self.mode == 'val' or self.mode == 'test':
            transform = transforms.Compose([
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) 
            ])
        
        x = self.load_sample(self.files[index])
        x = self._prepare_sample(x)
        x = np.array(x / 255, dtype='float32')
        x = transform(x)

        if self.mode == 'test':
            return x
        else:
            label = self.labels[index]
            label_id = self.label_encoder.transform([label])
            y = label_id.item()
            return x, y

from torchvision import transforms

transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.RandomRotation(degrees=(-10, 10), expand=True),
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.RandomResizedCrop(244),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) 
])

models_resnet101.load_state_dict(torch.load('/content/gdrive/MyDrive/Course_stepic_NN/Classification_picture/Home_work/Models/models_resnet101_26e.pth'))

optimizer = torch.optim.AdamW( params=[
        {"params": models_resnet101.conv1.parameters(), "lr": 1e-7},
        {"params": models_resnet101.bn1.parameters(), "lr": 1e-7},
        {"params": models_resnet101.maxpool.parameters(), "lr": 1e-7},
        {"params": models_resnet101.layer3.parameters(), "lr": 1e-7},
        {"params": models_resnet101.layer2.parameters(), "lr": 1e-6},
        {"params": models_resnet101.layer1.parameters(), "lr": 1e-4},
        {"params": models_resnet101.fc.parameters()},
    ], 
    lr=1e-4, amsgrad=True
)

from torch.optim import lr_scheduler

scheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)

train_dataset = AugmentSimpsonsDataset(train_files, mode='train', augmt_tfs=transform)
val_dataset = AugmentSimpsonsDataset(val_files, mode='val')

history = train(train_dataset, val_dataset, model=models_resnet101, epochs=5, batch_size=64, mdl_opt=optimizer, mdl_sheduler=scheduler)

torch.save(models_resnet101.state_dict(), '/content/gdrive/MyDrive/Course_stepic_NN/Classification_picture/Home_work/Models/models_resnet101_31e.pth')

from torch.optim import lr_scheduler

scheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)

train_dataset = AugmentSimpsonsDataset(train_files, mode='train', augmt_tfs=transform)
val_dataset = AugmentSimpsonsDataset(val_files, mode='val')

history = train(train_dataset, val_dataset, model=models_resnet101, epochs=5, batch_size=64, mdl_opt=optimizer, mdl_sheduler=scheduler)

torch.save(models_resnet101.state_dict(), '/content/gdrive/MyDrive/Course_stepic_NN/Classification_picture/Home_work/Models/models_resnet101_36e.pth')

import matplotlib.patches as patches
from matplotlib.font_manager import FontProperties

fig, ax = plt.subplots(nrows=3, ncols=3,figsize=(12, 12), \
                        sharey=True, sharex=True)
for fig_x in ax.flatten():
    random_characters = int(np.random.uniform(0,1000))
    im_val, label = val_dataset[random_characters]
    img_label = " ".join(map(lambda x: x.capitalize(),\
                val_dataset.label_encoder.inverse_transform([label])[0].split('_')))
   
     

    imshow(im_val.data.cpu(), \
          title=img_label,plt_ax=fig_x)
    
    actual_text = "Actual : {}".format(img_label)
            
    fig_x.add_patch(patches.Rectangle((0, 53),86,35,color='white'))
    font0 = FontProperties()
    font = font0.copy()
    font.set_family("fantasy")
    prob_pred = predict_one_sample(models_resnet101, im_val.unsqueeze(0))
    predicted_proba = np.max(prob_pred)*100
    y_pred = np.argmax(prob_pred)
    
    predicted_label = label_encoder.classes_[y_pred]
    predicted_label = predicted_label[:len(predicted_label)//2] + '\n' + predicted_label[len(predicted_label)//2:]
    predicted_text = "{} : {:.0f}%".format(predicted_label,predicted_proba)
            
    fig_x.text(1, 59, predicted_text , horizontalalignment='left', fontproperties=font,
                    verticalalignment='top',fontsize=8, color='black',fontweight='bold')

"""## Дообучение на балансированных классах """

from torchvision import models 
import torchvision

models_resnet101 = models.resnet101(pretrained=True)

num_features = 2048
n_classes = len(np.unique(train_val_labels))
models_resnet101.fc = nn.Linear(num_features, n_classes, bias=True)

models_resnet101 = models_resnet101.cuda()

for param in models_resnet101.parameters():
    param.requires_grad = True

class AugmentSimpsonsDataset(SimpsonsDataset):
    def __init__(self, files, mode, augmt_tfs=None):
        super().__init__(files, mode)
        self.augmt_tfs = augmt_tfs

    def __getitem__(self, index):

        if self.mode == 'train':
            transform = self.augmt_tfs

        if self.mode == 'val' or self.mode == 'test':
            transform = transforms.Compose([
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) 
            ])
        
        x = self.load_sample(self.files[index])
        x = self._prepare_sample(x)
        x = np.array(x / 255, dtype='float32')
        x = transform(x)

        if self.mode == 'test':
            return x
        else:
            label = self.labels[index]
            label_id = self.label_encoder.transform([label])
            y = label_id.item()
            return x, y

from torchvision import transforms

transform = transforms.Compose([
        transforms.ToTensor(),
        # transforms.RandomRotation(degrees=(-10, 10), expand=True),
        transforms.RandomHorizontalFlip(p=0.5),
        # transforms.RandomResizedCrop(244),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) 
])

models_resnet101.load_state_dict(torch.load('/content/gdrive/MyDrive/Course_stepic_NN/Classification_picture/Home_work/Models/models_resnet101_36e.pth'))

from torch.utils.data.sampler import SubsetRandomSampler, WeightedRandomSampler

val_dataset = AugmentSimpsonsDataset(val_files, mode='val')
train_dataset = AugmentSimpsonsDataset(train_files, mode='train')


train_dataset = SimpsonsDataset(train_files, mode='train')
# val_dataset = SimpsonsDataset(val_files, mode='val')
train_label = [train_dataset[id][1] for id in range(len(train_dataset))]
# val_label = [val_dataset[id][1] for id in range(len(val_dataset))]
# labels = np.array(train_label + val_label)
labels = np.array(train_label)
class_sample_count = np.array([len(np.where(labels==t)[0]) for t in np.unique(labels)])
weight = 1. / class_sample_count
samples_weight = np.array([weight[t] for t in labels])
samples_weight = torch.from_numpy(samples_weight)

def train(train_files, val_files, model, epochs, batch_size, mdl_opt, mdl_sheduler):
    train_loader = DataLoader(train_dataset, batch_size=batch_size, 
                              sampler=WeightedRandomSampler(samples_weight.type('torch.DoubleTensor'), len(samples_weight)), num_workers=2)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)

    history = []
    log_template = "\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \
    val_loss {v_loss:0.4f} train_acc {t_acc:0.4f} val_acc {v_acc:0.4f}"

    with tqdm(desc="epoch", total=epochs) as pbar_outer:
        opt = mdl_opt
        criterion = nn.CrossEntropyLoss()

        for epoch in range(epochs):
            train_loss, train_acc = fit_epoch(model, train_loader, criterion, opt, mdl_sheduler)
            print("loss", train_loss)
            
            val_loss, val_acc = eval_epoch(model, val_loader, criterion)
            history.append((train_loss, train_acc, val_loss, val_acc))
            
            pbar_outer.update(1)
            tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss,\
                                           v_loss=val_loss, t_acc=train_acc, v_acc=val_acc))
            
    return history

def fit_epoch(model, train_loader, criterion, optimizer, mdl_sheduler=None):
    running_loss = 0.0
    running_corrects = 0
    processed_data = 0
  
    for inputs, labels in train_loader:
        model.train()
        inputs = inputs.to(DEVICE)
        labels = labels.to(DEVICE)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        preds = torch.argmax(outputs, 1)
        running_loss += loss.item() * inputs.size(0)
        running_corrects += torch.sum(preds == labels.data)
        processed_data += inputs.size(0)

    mdl_sheduler.step()

    train_loss = running_loss / processed_data
    train_acc = running_corrects.cpu().numpy() / processed_data
    
    return train_loss, train_acc

optimizer = torch.optim.AdamW( params=[
        {"params": models_resnet101.conv1.parameters(), "lr": 1e-7},
        {"params": models_resnet101.bn1.parameters(), "lr": 1e-7},
        {"params": models_resnet101.maxpool.parameters(), "lr": 1e-7},
        {"params": models_resnet101.layer3.parameters(), "lr": 1e-7},
        {"params": models_resnet101.layer2.parameters(), "lr": 1e-6},
        {"params": models_resnet101.layer1.parameters(), "lr": 1e-4},
        {"params": models_resnet101.fc.parameters()},
    ], 
    lr=1e-4, amsgrad=True
)

from torch.optim import lr_scheduler

scheduler = lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.25)

train_dataset = AugmentSimpsonsDataset(train_files, mode='train', augmt_tfs=transform)
val_dataset = AugmentSimpsonsDataset(val_files, mode='val')

history = train(train_dataset, val_dataset, model=models_resnet101, epochs=3, batch_size=64, mdl_opt=optimizer, mdl_sheduler=scheduler)

label_encoder = pickle.load(open("label_encoder.pkl", 'rb'))

val_dataset = AugmentSimpsonsDataset(val_files, mode="val")
val_loader = DataLoader(val_dataset, shuffle=False, batch_size=256)
probs = val_predict(models_resnet101, val_loader)
label_preds = label_encoder.inverse_transform(np.argmax(probs, axis=1))

actual_labels = [val_dataset[id][1] for id in range(len(val_dataset))]
act_labels_prvd = [label_encoder.classes_[i] for i in actual_labels]

get_f1_score(act_labels_prvd, label_preds)

"""- Сделаем предикт на тестовых данных"""

preds, test_filenames = get_test_filenames(dataset=AugmentSimpsonsDataset, cnn=models_resnet101, batch_size=64)

"""- Сохраним предсказания"""

save_path = '/content/gdrive/MyDrive/Course_stepic_NN/Classification_picture/Home_work/resnet101_e42_bl.csv'

save_submit(test_filenames=test_filenames, preds=preds, save_path=save_path)

srav = save_submit(test_filenames=test_filenames, preds=preds, save_path=save_path)

srav